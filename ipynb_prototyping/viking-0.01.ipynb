{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GeneViking - prokkaViking protoype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "from Bio import SeqIO\n",
    "import io\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "\n",
    "__author__ = 'Natalia Quinones-Olvera'\n",
    "__email__ = \"nquinones@g.harvard.edu\"\n",
    "Entrez.email = __email__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Location parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_loc(loc, ref_start):\n",
    "    'Function to correctly parse location object'\n",
    "    # start\n",
    "    if str(type(loc.start)) == \"<class 'Bio.SeqFeature.ExactPosition'>\":\n",
    "        start = loc.start + ref_start\n",
    "        start_str = start\n",
    "    elif str(type(loc.start)) == \"<class 'Bio.SeqFeature.BeforePosition'>\":\n",
    "        start = loc.start + ref_start\n",
    "        start_str = '<' + str(start)\n",
    "    elif str(type(loc.start)) == \"<class 'Bio.SeqFeature.AfterPosition'>\":\n",
    "        start = loc.start + ref_start\n",
    "        start_str = '>' + str(start)\n",
    "    else:\n",
    "        start_str = 'unknown position type'\n",
    "\n",
    "    # end\n",
    "    if str(type(loc.end)) == \"<class 'Bio.SeqFeature.ExactPosition'>\":\n",
    "        end = loc.end + ref_start - 1\n",
    "        end_str = end\n",
    "    elif str(type(loc.end)) == \"<class 'Bio.SeqFeature.BeforePosition'>\":\n",
    "        end = loc.end + ref_start - 1 \n",
    "        end_str = '<' + str(end)\n",
    "    elif str(type(loc.end)) == \"<class 'Bio.SeqFeature.AfterPosition'>\":\n",
    "        end = loc.end + ref_start -1\n",
    "        end_str = '>' + str(end)\n",
    "    else:\n",
    "        end_str = 'unknown position type'\n",
    "\n",
    "    if loc.strand == 1:\n",
    "        strand = '+'\n",
    "    else:\n",
    "        strand = '-'\n",
    "\n",
    "    return [start, end, start_str, end_str, strand]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Protein coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prot_coords(protein_acc):\n",
    "    '''\n",
    "    Helper function to find protein coordinates from accession.\n",
    "    Has limited functionality\n",
    "    '''\n",
    "    # check if it is non-redundant\n",
    "    if protein_acc.find('WP') == 0:\n",
    "        print('Warning: Seems that you\\'re providing a non-redundant protein accession.')\n",
    "\n",
    "    # send request to NCBI protein database\n",
    "    epost = Entrez.epost('protein', id=protein_acc)\n",
    "    request = Entrez.read(epost)\n",
    "\n",
    "    response = Entrez.efetch(db='protein',\n",
    "                             webenv=request['WebEnv'],\n",
    "                             query_key=request['QueryKey'],\n",
    "                             rettype=\"gb\",\n",
    "                             retmode=\"text\")\n",
    "\n",
    "    response_io = io.StringIO(response.read())\n",
    "\n",
    "    feat_list = []\n",
    "\n",
    "    for gb_record in SeqIO.parse(response_io, \"genbank\"):\n",
    "        for feat in gb_record.features:\n",
    "            feat_list.append(feat.type)\n",
    "                # source feature\n",
    "            if feat.type == 'CDS':\n",
    "                coded_str = feat.qualifiers['coded_by'][0].split(':')\n",
    "                acc = coded_str[0]\n",
    "                coords = coded_str[1].split('..')\n",
    "                start = coords[0]\n",
    "                end = coords[1]\n",
    "\n",
    "    # if no CDS feature found, return error message\n",
    "    if 'CDS' not in feat_list:\n",
    "        print('Error: Couldn\\'t find CDS feature. Unable to find coordinates.')\n",
    "        return None\n",
    "\n",
    "    return acc, (start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GeneViking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_viking(acc, start, end, thresh, output):\n",
    "    '''\n",
    "    Main functionality.\n",
    "    '''\n",
    "    start_2 = start - thresh\n",
    "    end_2 = end + thresh\n",
    "\n",
    "    if start_2 < 0:\n",
    "        start_2 = 0\n",
    "\n",
    "    epost = Entrez.epost('nuccore', id=acc)\n",
    "    request = Entrez.read(epost)\n",
    "    response = Entrez.efetch(db='nuccore',\n",
    "                             webenv=request['WebEnv'],\n",
    "                             query_key=request['QueryKey'],\n",
    "                             rettype=\"gb\",\n",
    "                             retmode=\"text\",\n",
    "                             seq_start=start_2,\n",
    "                             seq_stop=end_2)\n",
    "\n",
    "    response_io = io.StringIO(response.read())\n",
    "\n",
    "    query_range = set(range(start, end))\n",
    "\n",
    "    all_l = []\n",
    "\n",
    "    for record in SeqIO.parse(response_io, 'genbank'):\n",
    "        for feat in record.features:\n",
    "            if feat.type == 'CDS':\n",
    "                if 'pseudo' not in feat.qualifiers:\n",
    "                    fstart, fend, fstart_str, fend_str, fstrand = parse_loc(feat.location, start_2)\n",
    "                    prot_id = feat.qualifiers['protein_id'][0]\n",
    "                    product = feat.qualifiers['product'][0]\n",
    "\n",
    "                    feat_range = set(range(fstart, fend))\n",
    "\n",
    "                    if len(query_range.intersection(feat_range)) == 0:\n",
    "                        status = ''\n",
    "                    else:\n",
    "                        status = '!'\n",
    "\n",
    "                    feats = [prot_id, product, fstart_str, fend_str, fstrand, status]\n",
    "\n",
    "                    all_l.append(feats)\n",
    "\n",
    "    df = pd.DataFrame(all_l)\n",
    "\n",
    "    df.columns = ['prot_acc', 'product', 'start', 'end', 'strand', 'query_overlap']\n",
    "\n",
    "    if output is not None:\n",
    "        df.to_csv(output, sep='\\t', index=None)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Single request download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_test01 = 'NZ_CP025054.1'\n",
    "start_test01 = 12910\n",
    "end_test01 = 13287\n",
    "thresh_test01 = 10000\n",
    "output = None\n",
    "download = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Rewrite modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class NCBIQuery:\n",
    "    \n",
    "    def __init__(self, acc, start, end, thresh):\n",
    "        \n",
    "        # ncbi accession\n",
    "        self.acc = acc\n",
    "        \n",
    "        # query range\n",
    "        self.query_range = set(range(start, end))\n",
    "        # query start\n",
    "        self.start = start\n",
    "        # query end\n",
    "        self.end = end\n",
    "        \n",
    "        # neighborhood start\n",
    "        self.rangestart = start - thresh\n",
    "        if self.rangestart < 0:\n",
    "            self.rangestart = 0\n",
    "        # neighborhood end\n",
    "        self.rangeend = end + thresh\n",
    "        \n",
    "    def parse_loc(self, loc, ref_start):\n",
    "        '''\n",
    "        Function to correctly parse location object\n",
    "        '''\n",
    "        \n",
    "        # start\n",
    "        if str(type(loc.start)) == \"<class 'Bio.SeqFeature.ExactPosition'>\":\n",
    "            start = loc.start + ref_start\n",
    "            start_str = start\n",
    "        elif str(type(loc.start)) == \"<class 'Bio.SeqFeature.BeforePosition'>\":\n",
    "            start = loc.start + ref_start\n",
    "            start_str = '<' + str(start)\n",
    "        elif str(type(loc.start)) == \"<class 'Bio.SeqFeature.AfterPosition'>\":\n",
    "            start = loc.start + ref_start\n",
    "            start_str = '>' + str(start)\n",
    "        else:\n",
    "            start_str = 'unknown position type'\n",
    "\n",
    "        # end\n",
    "        if str(type(loc.end)) == \"<class 'Bio.SeqFeature.ExactPosition'>\":\n",
    "            end = loc.end + ref_start - 1\n",
    "            end_str = end\n",
    "        elif str(type(loc.end)) == \"<class 'Bio.SeqFeature.BeforePosition'>\":\n",
    "            end = loc.end + ref_start - 1 \n",
    "            end_str = '<' + str(end)\n",
    "        elif str(type(loc.end)) == \"<class 'Bio.SeqFeature.AfterPosition'>\":\n",
    "            end = loc.end + ref_start -1\n",
    "            end_str = '>' + str(end)\n",
    "        else:\n",
    "            end_str = 'unknown position type'\n",
    "\n",
    "        if loc.strand == 1:\n",
    "            strand = '+'\n",
    "        else:\n",
    "            strand = '-'\n",
    "\n",
    "        return [start, end, start_str, end_str, strand]\n",
    "\n",
    "    \n",
    "    def get_gb(self):\n",
    "        '''\n",
    "        Requests genbank file with Entrez\n",
    "        '''\n",
    "        \n",
    "        epost = Entrez.epost('nuccore', id=self.acc)\n",
    "        request = Entrez.read(epost)\n",
    "\n",
    "        response = Entrez.efetch(db='nuccore',\n",
    "                                 webenv=request['WebEnv'],\n",
    "                                 query_key=request['QueryKey'],\n",
    "                                 rettype='gb',\n",
    "                                 retmode=\"text\",\n",
    "                                 seq_start=self.rangestart,\n",
    "                                 seq_stop=self.rangeend)\n",
    "\n",
    "        response_io = io.StringIO(response.read())\n",
    "\n",
    "        return response_io\n",
    "    \n",
    "    def parse_gb(self, file='get', output=None):\n",
    "        '''\n",
    "        Parse gb file. Extracts product information from\n",
    "        feature types: CDS, tRNA, rRNA, ncRNA, and repeat_region\n",
    "        and writes dataframe with output.\n",
    "        Can save table into tsv output\n",
    "        '''\n",
    "        \n",
    "        response_gb = self.get_gb()\n",
    "        \n",
    "        feats = []\n",
    "\n",
    "        for record in SeqIO.parse(response_gb, 'genbank'):\n",
    "            for feat in record.features:\n",
    "                # extract location object\n",
    "                fstart, fend, fstart_str, fend_str, fstrand = self.parse_loc(feat.location, self.rangestart)\n",
    "                # save range\n",
    "                feat_range = set(range(fstart, fend))\n",
    "\n",
    "                # check overlap\n",
    "                if len(self.query_range.intersection(feat_range)) == 0:\n",
    "                    status = ''\n",
    "                else:\n",
    "                    status = '!'\n",
    "\n",
    "\n",
    "                if feat.type == 'CDS':\n",
    "                    if 'pseudo' not in feat.qualifiers:\n",
    "                        prot_id = feat.qualifiers['protein_id'][0]\n",
    "                        product = feat.qualifiers['product'][0]\n",
    "\n",
    "                        feat_info = [feat.type, prot_id, product, fstart_str, fend_str, fstrand, status]\n",
    "\n",
    "                    else:\n",
    "                        prot_id = 'None'\n",
    "                        product = feat.qualifiers['product'][0]\n",
    "\n",
    "                        feat_info = ['CDS_pseudo', prot_id, product, fstart_str, fend_str, fstrand, status]\n",
    "\n",
    "                    feats.append(feat_info)\n",
    "\n",
    "                if feat.type in ['tRNA', 'rRNA', 'ncRNA', 'repeat_region']:\n",
    "                    product = feat.qualifiers['product'][0]\n",
    "\n",
    "                    feat_info = [feat.type, None, product, fstart_str, fend_str, fstrand, status]\n",
    "\n",
    "                    feats.append(feat_info)\n",
    " \n",
    "        df = pd.DataFrame(feats)\n",
    "\n",
    "        df.columns = ['type', 'acc', 'product', 'start', 'end', 'strand', 'query_overlap']\n",
    "\n",
    "        if output is not None:\n",
    "            df.to_csv(output, sep='\\t', index=None)\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def get_fasta(self):\n",
    "        '''\n",
    "        Requests fasta file with Entrez\n",
    "        '''\n",
    "        epost = Entrez.epost('nuccore', id=self.acc)\n",
    "        request = Entrez.read(epost)\n",
    "\n",
    "        response = Entrez.efetch(db='nuccore',\n",
    "                                 webenv=request['WebEnv'],\n",
    "                                 query_key=request['QueryKey'],\n",
    "                                 rettype='fasta',\n",
    "                                 retmode=\"text\",\n",
    "                                 seq_start=self.rangestart,\n",
    "                                 seq_stop=self.rangeend)\n",
    "\n",
    "        response_io = io.StringIO(response.read())\n",
    "        \n",
    "        return response_io\n",
    "    \n",
    "    def parse_fasta(self, directory='.', file=None):\n",
    "        '''\n",
    "        Parses fasta file from Entrez request, saves\n",
    "        into output\n",
    "        '''\n",
    "        response_fasta = self.get_fasta()\n",
    "        \n",
    "        for record in SeqIO.parse(response_fasta, 'fasta'):\n",
    "            fastarecord = record\n",
    "            \n",
    "        # save output\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        \n",
    "        if file is None:\n",
    "            name = '{}.fa'.format(fastarecord.id.replace(':', '_'))\n",
    "            output = os.path.join(directory, name)\n",
    "        else:\n",
    "            output = os.path.join(directory, file)\n",
    "        \n",
    "        SeqIO.write(fastarecord, output, 'fasta')\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def run_prokka(self, directory):\n",
    "        '''\n",
    "        '''\n",
    "        file = self.parse_fasta(directory=directory)\n",
    "        \n",
    "        name = '{}_{}-{}'.format(self.acc, self.rangestart, self.rangeend)\n",
    "        \n",
    "        prokka_dir = os.path.join(directory, 'prokka')\n",
    "        \n",
    "        process = subprocess.run(['prokka', '--outdir', prokka_dir, '--prefix', name, file],\n",
    "                                 stdout=subprocess.PIPE,\n",
    "                                 stderr=subprocess.PIPE,\n",
    "                                 universal_newlines=True)\n",
    "        \n",
    "        if process.returncode != 0:\n",
    "            print('ERROR: {} \\n {}'.format(process.returncode, process.stderr))\n",
    "        else:\n",
    "            print('Done. Saved in: {}'.format(prokka_dir))\n",
    "            \n",
    "            gbk_path = '{}/{}.gbk'.format(prokka_dir, name)\n",
    "            \n",
    "            df = self.parse_gb(self, file=gbk_path, output=None)\n",
    "            \n",
    "            return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Viking:\n",
    "    \n",
    "    def __init__(self, entries, annot='ncbi'):\n",
    "        self.annot = annot\n",
    "        \n",
    "        if self.annot in ['ncbi', 'prokka']:\n",
    "            pass\n",
    "        else:\n",
    "            print('ERROR: Unrecognized annotation type.')\n",
    "        \n",
    "        self.entries = entries\n",
    "        \n",
    "        if not type(self.entries) == list:\n",
    "            raise ValueError('entries should be a list of NCBIQuery objects')\n",
    "        \n",
    "        for entry in self.entries:\n",
    "            if not isinstance(entry, NCBIQuery):\n",
    "                raise ValueError('entries should be a list of NCBIQuery objects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = NCBIQuery('CP025053.1', 701514, 702401, 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a.parse_gb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Saved in: tmp/prokka\n",
      "tmp/prokka/CP025053.1_651514-752401.gbk\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "parse_gb() got multiple values for argument 'file'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-754a2a936970>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_prokka\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tmp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-6d3cd97e68d1>\u001b[0m in \u001b[0;36mrun_prokka\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgbk_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_gb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgbk_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: parse_gb() got multiple values for argument 'file'"
     ]
    }
   ],
   "source": [
    "a.run_prokka('tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -r tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = Viking([a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
